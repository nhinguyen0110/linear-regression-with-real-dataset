{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNav1rEzxSdxmNgvyvE9X/S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oySXbN25l8OW"},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","source":["#@title Import relevant modules\n","import pandas as pd\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","\n","# The following lines adjust the granularity of reporting.\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = \"{:.1f}\".format"],"metadata":{"id":"PDzLt3_MmUVQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the dataset.\n","training_df = pd.read_csv(filepath_or_buffer=\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n","\n","# Scale the label.\n","training_df[\"median_house_value\"] /= 1000.0\n","\n","# Print the first rows of the pandas DataFrame.\n","training_df.head()"],"metadata":{"id":"ufea7_uBmeR-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get statistics on the dataset.\n","training_df.describe()"],"metadata":{"id":"-f_vVrY4mg_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The maximum value (max) of several columns seems very\n","# high compared to the other quantiles. For example,\n","# example the total_rooms column. Given the quantile\n","# values (25%, 50%, and 75%), you might expect the\n","# max value of total_rooms to be approximately\n","# 5,000 or possibly 10,000. However, the max value\n","# is actually 37,937.\n","\n","# When you see anomalies in a column, become more careful\n","# about using that column as a feature. That said,\n","# anomalies in potential features sometimes mirror\n","# anomalies in the label, which could make the column\n","# be (or seem to be) a powerful feature.\n","# Also, as you will see later in the course, you\n","# might be able to represent (pre-process) raw data\n","# in order to make columns into useful features."],"metadata":{"id":"cL-ITnknmjje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Define the functions that build and train a model\n","def build_model(my_learning_rate):\n","  \"\"\"Create and compile a simple linear regression model.\"\"\"\n","  # Most simple tf.keras models are sequential.\n","  model = tf.keras.models.Sequential()\n","\n","  # Describe the topography of the model.\n","  # The topography of a simple linear regression model\n","  # is a single node in a single layer.\n","  model.add(tf.keras.layers.Dense(units=1,\n","                                  input_shape=(1,)))\n","\n","  # Compile the model topography into code that TensorFlow can efficiently\n","  # execute. Configure training to minimize the model's mean squared error.\n","  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n","                loss=\"mean_squared_error\",\n","                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","  return model\n","\n","\n","def train_model(model, df, feature, label, epochs, batch_size):\n","  \"\"\"Train the model by feeding it data.\"\"\"\n","\n","  # Feed the model the feature and the label.\n","  # The model will train for the specified number of epochs.\n","  history = model.fit(x=df[feature],\n","                      y=df[label],\n","                      batch_size=batch_size,\n","                      epochs=epochs)\n","\n","  # Gather the trained model's weight and bias.\n","  trained_weight = model.get_weights()[0]\n","  trained_bias = model.get_weights()[1]\n","\n","  # The list of epochs is stored separately from the rest of history.\n","  epochs = history.epoch\n","\n","  # Isolate the error for each epoch.\n","  hist = pd.DataFrame(history.history)\n","\n","  # To track the progression of training, we're going to take a snapshot\n","  # of the model's root mean squared error at each epoch.\n","  rmse = hist[\"root_mean_squared_error\"]\n","\n","  return trained_weight, trained_bias, epochs, rmse\n","\n","print(\"Defined the build_model and train_model functions.\")"],"metadata":{"id":"-fPEn7comrE9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Define the plotting functions\n","def plot_the_model(trained_weight, trained_bias, feature, label):\n","  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n","\n","  # Label the axes.\n","  plt.xlabel(feature)\n","  plt.ylabel(label)\n","\n","  # Create a scatter plot from 200 random points of the dataset.\n","  random_examples = training_df.sample(n=200)\n","  plt.scatter(random_examples[feature], random_examples[label])\n","\n","  # Create a red line representing the model. The red line starts\n","  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n","  x0 = 0\n","  y0 = trained_bias\n","  x1 = random_examples[feature].max()\n","  y1 = trained_bias + (trained_weight * x1)\n","  plt.plot([x0, x1], [y0, y1], c='r')\n","\n","  # Render the scatter plot and the red line.\n","  plt.show()\n","\n","\n","def plot_the_loss_curve(epochs, rmse):\n","  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n","\n","  plt.figure()\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Root Mean Squared Error\")\n","\n","  plt.plot(epochs, rmse, label=\"Loss\")\n","  plt.legend()\n","  plt.ylim([rmse.min()*0.97, rmse.max()])\n","  plt.show()\n","\n","print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"],"metadata":{"id":"gn2f2rtsmu4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The following variables are the hyperparameters.\n","learning_rate = 0.01\n","epochs = 30\n","batch_size = 30\n","\n","# Specify the feature and the label.\n","my_feature = \"total_rooms\"  # the total number of rooms on a specific city block.\n","my_label=\"median_house_value\" # the median value of a house on a specific city block.\n","# That is, you're going to create a model that predicts house value based\n","# solely on total_rooms.\n","\n","# Discard any pre-existing version of the model.\n","my_model = None\n","\n","# Invoke the functions.\n","my_model = build_model(learning_rate)\n","weight, bias, epochs, rmse = train_model(my_model, training_df,\n","                                         my_feature, my_label,\n","                                         epochs, batch_size)\n","\n","print(\"\\nThe learned weight for your model is %.4f\" % weight)\n","print(\"The learned bias for your model is %.4f\\n\" % bias )\n","\n","plot_the_model(weight, bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)"],"metadata":{"id":"lax-TI4Imx3E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_house_values(n, feature, label):\n","  \"\"\"Predict house values based on a feature.\"\"\"\n","\n","  batch = training_df[feature][10000:10000 + n]\n","  predicted_values = my_model.predict_on_batch(x=batch)\n","\n","  print(\"feature   label          predicted\")\n","  print(\"  value   value          value\")\n","  print(\"          in thousand$   in thousand$\")\n","  print(\"--------------------------------------\")\n","  for i in range(n):\n","    print (\"%5.0f %6.0f %15.0f\" % (training_df[feature][10000 + i],\n","                                   training_df[label][10000 + i],\n","                                   predicted_values[i][0] ))"],"metadata":{"id":"povhfMDwm1ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_house_values(10, my_feature, my_label)"],"metadata":{"id":"HpeTHIsem41t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Most of the predicted values differ significantly\n","# from the label value, so the trained model probably\n","# doesn't have much predictive power. However, the\n","# first 10 examples might not be representative of\n","# the rest of the examples."],"metadata":{"id":"0gVdvJ4tm7ZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_feature = \"population\" # Pick a feature other than \"total_rooms\"\n","\n","# Possibly, experiment with the hyperparameters.\n","learning_rate = 0.05\n","epochs = 18\n","batch_size = 3\n","\n","# Don't change anything below.\n","my_model = build_model(learning_rate)\n","weight, bias, epochs, rmse = train_model(my_model, training_df,\n","                                         my_feature, my_label,\n","                                         epochs, batch_size)\n","\n","plot_the_model(weight, bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)\n","\n","predict_house_values(10, my_feature, my_label)"],"metadata":{"id":"tXfFbW7rm_t0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training is not entirely deterministic, but population\n","# typically converges at a slightly higher RMSE than\n","# total_rooms.  So, population appears to be about\n","# the same or slightly worse at making predictions\n","# than total_rooms."],"metadata":{"id":"MSfqKU4hnEBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a synthetic feature\n","training_df[\"rooms_per_person\"] = training_df[\"total_rooms\"] / training_df[\"population\"]\n","my_feature = \"rooms_per_person\"\n","\n","# Tune the hyperparameters.\n","learning_rate = 0.06\n","epochs = 24\n","batch_size = 30\n","\n","# Don't change anything below this line.\n","my_model = build_model(learning_rate)\n","weight, bias, epochs, mae = train_model(my_model, training_df,\n","                                        my_feature, my_label,\n","                                        epochs, batch_size)\n","\n","plot_the_loss_curve(epochs, mae)\n","predict_house_values(15, my_feature, my_label)"],"metadata":{"id":"g2ERss23nHgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate a correlation matrix.\n","training_df.corr()"],"metadata":{"id":"KuOdfmpfnQtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The median_income correlates 0.7 with the label\n","# (median_house_value), so median_income might be a\n","# good feature. The other seven potential features\n","# all have a correlation relatively close to 0.\n","\n","# If time permits, try median_income as the feature\n","# and see whether the model improves."],"metadata":{"id":"P07EfcpanTTb"},"execution_count":null,"outputs":[]}]}